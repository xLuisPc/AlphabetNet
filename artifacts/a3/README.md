# Artifacts A3 - Predicciones de Continuaciones

Este directorio contiene las predicciones del modelo AlphabetNet (A2) sobre los datasets de validaciÃ³n y test de continuaciones (A1).

## ğŸ“ Archivos Generados

### `preds_val.parquet`
Predicciones sobre el conjunto de validaciÃ³n.
- **Filas**: 5,544 ejemplos
- **Columnas**: 38 (dfa_id, prefix, + 12 p_hat + 12 y_true + 12 support)

### `preds_test.parquet`
Predicciones sobre el conjunto de test.
- **Filas**: 5,935 ejemplos
- **Columnas**: 38 (dfa_id, prefix, + 12 p_hat + 12 y_true + 12 support)

## ğŸ“Š Estructura de los Archivos

Cada archivo parquet contiene las siguientes columnas:

### Columnas BÃ¡sicas
- **`dfa_id`** (int): ID del autÃ³mata (0-2999)
- **`prefix`** (str): Prefijo de la cadena (ej: "ABC", "<EPS>")

### Columnas de Probabilidades Predichas (p_hat)
- **`p_hat_A`** a **`p_hat_L`** (float): Probabilidades predichas por el modelo para cada sÃ­mbolo
  - Rango: [0.0, 1.0]
  - Representa P(sÃ­mbolo puede continuar | prefijo)

### Columnas de Etiquetas Verdaderas (y_true)
- **`y_true_A`** a **`y_true_L`** (int): Etiquetas verdaderas multi-hot
  - Valores: 0 (sÃ­mbolo NO puede continuar) o 1 (sÃ­mbolo SÃ puede continuar)
  - ExtraÃ­das del dataset de continuations de A1

### Columnas de Soporte (support)
- **`support_A`** a **`support_L`** (int): NÃºmero de veces que se observÃ³ cada continuaciÃ³n
  - Valores: â‰¥ 0
  - Indica cuÃ¡ntas cadenas positivas del autÃ³mata tienen este prefijo seguido de este sÃ­mbolo
  - Ãštil para anÃ¡lisis ponderado por frecuencia

## ğŸ”§ CÃ³mo se Generaron

```bash
python tools/generate_a3_predictions.py \
  --checkpoint "novTest/best (1).pt" \
  --output_dir "artifacts/a3" \
  --batch_size 256
```

### Modelo Utilizado
- **Checkpoint**: `novTest/best (1).pt`
- **Ã‰poca**: 5
- **F1 Macro**: 1.0 (en dataset de entrenamiento regexâ†’alfabeto)
- **F1 Min**: 1.0
- **ECE**: 0.599

### Dataset de Entrada
- **Continuations**: `data/alphabet/continuations.parquet`
- **Splits**: `data/alphabet/splits_automata.json`
- **Val autÃ³matas**: 296
- **Test autÃ³matas**: 296

## ğŸ“ˆ Uso de los Datos

### Cargar predicciones

```python
import pandas as pd

# Cargar validaciÃ³n
df_val = pd.read_parquet('artifacts/a3/preds_val.parquet')

# Cargar test
df_test = pd.read_parquet('artifacts/a3/preds_test.parquet')

print(f"Val: {len(df_val):,} ejemplos")
print(f"Test: {len(df_test):,} ejemplos")
```

### Extraer probabilidades y etiquetas

```python
import numpy as np

# SÃ­mbolos del alfabeto
ALPHABET = list('ABCDEFGHIJKL')

# Extraer probabilidades predichas (p_hat)
p_hat_cols = [f'p_hat_{sym}' for sym in ALPHABET]
p_hat = df_val[p_hat_cols].values  # Shape: (n_samples, 12)

# Extraer etiquetas verdaderas (y_true)
y_true_cols = [f'y_true_{sym}' for sym in ALPHABET]
y_true = df_val[y_true_cols].values  # Shape: (n_samples, 12)

# Extraer soporte
support_cols = [f'support_{sym}' for sym in ALPHABET]
support = df_val[support_cols].values  # Shape: (n_samples, 12)
```

### Calcular mÃ©tricas

```python
from sklearn.metrics import average_precision_score, f1_score

# Average Precision por sÃ­mbolo
ap_per_symbol = {}
for i, sym in enumerate(ALPHABET):
    ap = average_precision_score(y_true[:, i], p_hat[:, i])
    ap_per_symbol[sym] = ap

# Macro Average Precision
macro_ap = np.mean(list(ap_per_symbol.values()))
print(f"Macro auPRC: {macro_ap:.4f}")

# F1-score con threshold 0.5
y_pred = (p_hat >= 0.5).astype(int)
f1_macro = f1_score(y_true, y_pred, average='macro')
print(f"F1 Macro (threshold=0.5): {f1_macro:.4f}")
```

### AnÃ¡lisis por autÃ³mata

```python
# Agrupar por autÃ³mata
for dfa_id in df_val['dfa_id'].unique()[:5]:  # Primeros 5 autÃ³matas
    df_dfa = df_val[df_val['dfa_id'] == dfa_id]
    print(f"\nAutÃ³mata {dfa_id}:")
    print(f"  Prefijos: {len(df_dfa)}")
    print(f"  Longitud promedio: {df_dfa['prefix'].str.len().mean():.1f}")
```

### AnÃ¡lisis ponderado por soporte

```python
# Calcular mÃ©tricas ponderadas por soporte
for i, sym in enumerate(ALPHABET):
    # Filtrar solo ejemplos donde el sÃ­mbolo es positivo
    mask = y_true[:, i] == 1
    if mask.sum() == 0:
        continue
    
    # Probabilidades y soporte para este sÃ­mbolo
    probs = p_hat[mask, i]
    weights = support[mask, i]
    
    # Promedio ponderado de probabilidades
    weighted_avg_prob = np.average(probs, weights=weights)
    print(f"{sym}: {weighted_avg_prob:.4f}")
```

## ğŸ¯ PropÃ³sito

Estos archivos son para el anÃ¡lisis A3, que evalÃºa:
1. **CalibraciÃ³n**: Â¿Las probabilidades predichas reflejan la frecuencia real?
2. **DiscriminaciÃ³n**: Â¿El modelo separa bien continuaciones vÃ¡lidas de invÃ¡lidas?
3. **Consistencia**: Â¿Las predicciones son consistentes dentro de un mismo autÃ³mata?
4. **GeneralizaciÃ³n**: Â¿El modelo generaliza bien a autÃ³matas no vistos en entrenamiento?

## ğŸ“Š Resultados

Ver `RESULTADOS.md` para un anÃ¡lisis detallado de las mÃ©tricas y observaciones.

**Resumen rÃ¡pido**:
- **Macro auPRC**: 0.6518 (val), 0.6652 (test)
- **F1 Macro** (threshold=0.9): 0.6321 (val), 0.6625 (test)
- **Mejor rendimiento**: Prefijos de longitud 5-14
- **Threshold Ã³ptimo**: 0.9 (alta precisiÃ³n, recall moderado)

## ğŸ“ Notas

- El modelo fue entrenado en la tarea de **regex â†’ alfabeto completo**, no en la tarea de **prefijo â†’ continuaciones**.
- Sin embargo, las predicciones pueden ser Ãºtiles para analizar si el modelo captura la estructura de los autÃ³matas.
- El soporte (`support_[A-L]`) indica la frecuencia de cada continuaciÃ³n en el dataset original.
- Prefijos con `<EPS>` representan el inicio de una cadena (sin caracteres previos).

## ğŸ”— Referencias

- **A1 (Continuations)**: `data/alphabet/continuations.parquet`
- **A2 (Modelo)**: `novTest/best (1).pt`
- **Script de generaciÃ³n**: `tools/generate_a3_predictions.py`
- **Splits**: `data/alphabet/splits_automata.json`

