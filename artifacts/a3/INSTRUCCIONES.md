# Instrucciones para Entregar A3

## âœ… Archivos Generados

Los siguientes archivos han sido generados y estÃ¡n listos para entregar:

### 1. `artifacts/a3/preds_val.parquet`
- **TamaÃ±o**: ~0.20 MB
- **Filas**: 5,544 ejemplos
- **Columnas**: 38
  - `dfa_id`: ID del autÃ³mata
  - `prefix`: Prefijo de la cadena
  - `p_hat_A` a `p_hat_L`: Probabilidades predichas (12 columnas)
  - `y_true_A` a `y_true_L`: Etiquetas verdaderas (12 columnas)
  - `support_A` a `support_L`: Soporte por sÃ­mbolo (12 columnas)

### 2. `artifacts/a3/preds_test.parquet`
- **TamaÃ±o**: ~0.20 MB
- **Filas**: 5,935 ejemplos
- **Columnas**: 38 (misma estructura que val)

## ğŸ”§ CÃ³mo se Generaron

```bash
python tools/generate_a3_predictions.py \
  --checkpoint "novTest/best (1).pt" \
  --output_dir "artifacts/a3" \
  --batch_size 256
```

### Modelo Utilizado
- **Checkpoint**: `novTest/best (1).pt` (Ã©poca 5)
- **F1 Macro**: 1.0 (en dataset de entrenamiento regexâ†’alfabeto)
- **Arquitectura**: RNN (GRU) con embeddings

### Dataset de Entrada
- **Continuations**: `data/alphabet/continuations.parquet`
- **Splits**: `data/alphabet/splits_automata.json`
- **Val**: 296 autÃ³matas, 5,544 ejemplos
- **Test**: 296 autÃ³matas, 5,935 ejemplos

## ğŸ“Š MÃ©tricas Principales

### Macro Average Precision (auPRC)
- **ValidaciÃ³n**: 0.6518
- **Test**: 0.6652

### F1-Score (threshold=0.9)
- **ValidaciÃ³n**: 0.6321 (Precision: 0.86, Recall: 0.50)
- **Test**: 0.6625 (Precision: 0.86, Recall: 0.54)

## ğŸ“ Estructura de Entrega

```
artifacts/a3/
â”œâ”€â”€ preds_val.parquet      # Predicciones de validaciÃ³n
â”œâ”€â”€ preds_test.parquet     # Predicciones de test
â”œâ”€â”€ README.md              # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ RESULTADOS.md          # AnÃ¡lisis detallado de mÃ©tricas
â””â”€â”€ INSTRUCCIONES.md       # Este archivo
```

## ğŸ” Verificar los Archivos

### Cargar y verificar estructura

```python
import pandas as pd

# Cargar archivos
df_val = pd.read_parquet('artifacts/a3/preds_val.parquet')
df_test = pd.read_parquet('artifacts/a3/preds_test.parquet')

# Verificar estructura
print("ValidaciÃ³n:")
print(f"  Filas: {len(df_val):,}")
print(f"  Columnas: {len(df_val.columns)}")
print(f"  Columnas: {df_val.columns.tolist()[:5]} ...")

print("\nTest:")
print(f"  Filas: {len(df_test):,}")
print(f"  Columnas: {len(df_test.columns)}")

# Verificar que no hay NaN
print(f"\nNaN en val: {df_val.isna().sum().sum()}")
print(f"NaN en test: {df_test.isna().sum().sum()}")

# Verificar rangos
print(f"\nRango de probabilidades (val): [{df_val.filter(like='p_hat').min().min():.4f}, {df_val.filter(like='p_hat').max().max():.4f}]")
print(f"Rango de probabilidades (test): [{df_test.filter(like='p_hat').min().min():.4f}, {df_test.filter(like='p_hat').max().max():.4f}]")
```

### AnÃ¡lisis de mÃ©tricas

```bash
# Ejecutar anÃ¡lisis completo
python tools/analyze_a3_predictions.py
```

## ğŸ“¤ QuÃ© Entregar

### Archivos Requeridos
1. `artifacts/a3/preds_val.parquet` âœ…
2. `artifacts/a3/preds_test.parquet` âœ…

### Archivos Opcionales (DocumentaciÃ³n)
3. `artifacts/a3/README.md` - DocumentaciÃ³n tÃ©cnica
4. `artifacts/a3/RESULTADOS.md` - AnÃ¡lisis de mÃ©tricas
5. `tools/generate_a3_predictions.py` - Script de generaciÃ³n
6. `tools/analyze_a3_predictions.py` - Script de anÃ¡lisis

## ğŸ¯ Cumplimiento de Requisitos

### âœ… Columnas Requeridas
- [x] `dfa_id`: ID del autÃ³mata
- [x] `prefix`: Prefijo de la cadena
- [x] `p_hat_[A..L]`: Probabilidades predichas (12 columnas)
- [x] `y_true_[A..L]`: Etiquetas verdaderas multi-hot (12 columnas, opcional)
- [x] `support_[A..L]`: Soporte por sÃ­mbolo (12 columnas)

### âœ… Formato
- [x] Formato Parquet
- [x] Nombres de archivo: `preds_val.parquet`, `preds_test.parquet`
- [x] UbicaciÃ³n: `artifacts/a3/`

### âœ… Datos
- [x] Predicciones sobre splits de validaciÃ³n y test
- [x] Splits basados en `data/alphabet/splits_automata.json`
- [x] Modelo A2: `novTest/best (1).pt`
- [x] Datos A1: `data/alphabet/continuations.parquet`

## ğŸ“ Notas Importantes

1. **Tarea del modelo**: El modelo fue entrenado para predecir el alfabeto completo desde un regex, no para predecir continuaciones desde prefijos. Por eso el rendimiento es moderado (~0.65 auPRC).

2. **Threshold**: El threshold Ã³ptimo encontrado es 0.9, que da alta precisiÃ³n (0.86) pero recall moderado (0.50-0.54).

3. **Rendimiento por longitud**: El modelo funciona mejor con prefijos de longitud 5-14 (F1 â‰ˆ 0.73-0.78) y peor con prefijos vacÃ­os (F1 â‰ˆ 0.19-0.21).

4. **GeneralizaciÃ³n**: El modelo generaliza bien de validaciÃ³n a test (auPRC: 0.6518 â†’ 0.6652), sin evidencia de sobreajuste.

## ğŸš€ Re-generar si es Necesario

Si necesitas re-generar los archivos (por ejemplo, con un modelo diferente):

```bash
# Con otro checkpoint
python tools/generate_a3_predictions.py \
  --checkpoint "ruta/a/otro/checkpoint.pt" \
  --output_dir "artifacts/a3" \
  --batch_size 256

# Con otro dataset de continuations
python tools/generate_a3_predictions.py \
  --checkpoint "novTest/best (1).pt" \
  --continuations "ruta/a/otro/continuations.parquet" \
  --output_dir "artifacts/a3"
```

## âœ… Checklist Final

Antes de entregar, verifica:
- [ ] Los archivos `preds_val.parquet` y `preds_test.parquet` existen en `artifacts/a3/`
- [ ] Ambos archivos tienen 38 columnas (dfa_id, prefix, 12 p_hat, 12 y_true, 12 support)
- [ ] No hay valores NaN en las columnas crÃ­ticas
- [ ] Las probabilidades estÃ¡n en el rango [0, 1]
- [ ] Los y_true son 0 o 1
- [ ] Los support son enteros no negativos
- [ ] Has revisado `RESULTADOS.md` para entender las mÃ©tricas

## ğŸ“ Soporte

Si tienes problemas:
1. Revisa `README.md` para documentaciÃ³n tÃ©cnica
2. Revisa `RESULTADOS.md` para anÃ¡lisis de mÃ©tricas
3. Ejecuta `python tools/analyze_a3_predictions.py` para verificar
4. Revisa los logs de generaciÃ³n para errores

