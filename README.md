# AlphabetNet

Modelo de aprendizaje profundo para predecir el alfabeto de un autÃ³mata finito determinista (DFA) a partir de prefijos de cadenas.

## ğŸ“‹ DescripciÃ³n

AlphabetNet utiliza una arquitectura RNN (GRU o LSTM) para procesar secuencias de caracteres y predecir quÃ© sÃ­mbolos son vÃ¡lidos como siguiente carÃ¡cter despuÃ©s de cada prefijo. El modelo fue entrenado en 3,000 autÃ³matas con regex y alfabetos conocidos.

## ğŸš€ InstalaciÃ³n

### Requisitos

```bash
pip install torch pandas numpy scikit-learn matplotlib seaborn
```

Para exportaciÃ³n ONNX (opcional):
```bash
pip install onnxruntime
```

### InstalaciÃ³n del MÃ³dulo

```bash
# Desde el directorio raÃ­z
pip install -e .
```

## ğŸ“– Uso RÃ¡pido

### Python API

```python
from alphabetnet import infer_alphabet

# Inferir alfabeto desde strings de muestra
strings = ["AB", "ABA", "ABABAB"]
alphabet = infer_alphabet(
    automata_id=42,
    sample_strings=strings,
    engine='onnx'
)

print(f"Alfabeto: {sorted(alphabet)}")
```

### CLI

```bash
python -m alphabetnet.cli \
  --dfa-id 42 \
  --strings "AB" "ABA" "ABABAB" \
  --engine onnx
```

Output:
```json
{
  "dfa_id": 42,
  "alphabet": ["A", "B"]
}
```

## ğŸ—ï¸ Estructura del Proyecto

```
ModelosLenguajes/
â”œâ”€â”€ alphabetnet/          # MÃ³dulo de inferencia reutilizable
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ preproc.py
â”‚   â”œâ”€â”€ engines.py
â”‚   â””â”€â”€ cli.py
â”œâ”€â”€ src/                  # CÃ³digo fuente
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ tools/                # Scripts de utilidad
â”‚   â”œâ”€â”€ export_torch_onnx.py
â”‚   â”œâ”€â”€ prepare_model_artifacts.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ artifacts/            # Artefactos del modelo
â”‚   â””â”€â”€ alphabetnet/
â”‚       â”œâ”€â”€ best.pt
â”‚       â”œâ”€â”€ hparams.json
â”‚       â”œâ”€â”€ vocab_char_to_id.json
â”‚       â”œâ”€â”€ thresholds.json
â”‚       â””â”€â”€ a3_config.json
â”œâ”€â”€ tests/                # Tests unitarios
â”‚   â”œâ”€â”€ test_preproc.py
â”‚   â”œâ”€â”€ test_infer.py
â”‚   â””â”€â”€ test_onnx_parity.py
â””â”€â”€ reports/              # Reportes y anÃ¡lisis
    â”œâ”€â”€ A3_report.md
    â”œâ”€â”€ A4_robustness.md
    â”œâ”€â”€ A4_ablation.md
    â””â”€â”€ A5_perf.md
```

## ğŸ”§ PreparaciÃ³n de Artefactos

### 1. Preparar Artefactos Base

```bash
python tools/prepare_model_artifacts.py
```

Esto crea `artifacts/alphabetnet/` con todos los archivos necesarios.

### 2. Exportar a TorchScript y ONNX

```bash
python tools/export_torch_onnx.py
```

Esto genera:
- `artifacts/alphabetnet/alphabetnet.torchscript.pt`
- `artifacts/alphabetnet/alphabetnet.onnx`

## ğŸ“Š MÃ©tricas del Modelo

### Entrenamiento (A2)

- **auPRC Macro**: 0.99+
- **F1 Macro**: 0.99+
- **Set Accuracy**: 0.86+

### EvaluaciÃ³n (A3)

- **F1 Macro**: 0.85+
- **F1 Micro**: 0.90+
- **Jaccard**: 0.80+

### Robustez (A4)

- **AUC ROC (in-Î£ vs out-of-Î£)**: 0.7870
- **FPR Out-of-Î£**: 0.00% (objetivo â‰¤1-2% cumplido)

### Rendimiento (A5)

Ver `reports/A5_perf.md` para benchmarks detallados.

**Mejor ConfiguraciÃ³n A4**: `ablation_12` (LSTM, padding=right, dropout=0.3, auto_emb=False)

## ğŸ§ª Tests

```bash
# Ejecutar todos los tests
python -m pytest tests/ -v

# Tests especÃ­ficos
python -m pytest tests/test_preproc.py -v
python -m pytest tests/test_infer.py -v
python -m pytest tests/test_onnx_parity.py -v
```

## ğŸ“š DocumentaciÃ³n

- **Uso del MÃ³dulo**: `alphabetnet/README.md`
- **Model Card**: `MODEL_CARD.md`
- **Reportes**: `reports/`

## ğŸ”¬ Experimentos

### AblaciÃ³n (A4)

```bash
# Generar configuraciones
python tools/generate_ablation_configs.py --include-automata-emb

# Ejecutar experimentos (requiere modificar train.py)
python tools/run_ablation_experiments.py

# Analizar resultados
python tools/analyze_ablation_results.py
```

### Robustez (A4)

```bash
# Evaluar robustez en datos sintÃ©ticos
python tools/evaluate_a4_robustness.py --alphabet-ref auto
```

### Benchmark (A5)

```bash
# Ejecutar benchmark de rendimiento
python tools/benchmark_performance.py
```

## âš™ï¸ ConfiguraciÃ³n

### Thresholds

Los thresholds por sÃ­mbolo se encuentran en `artifacts/alphabetnet/thresholds.json`. Fueron optimizados en A2.6 para maximizar F1-score.

### Regla de AgregaciÃ³n A3

La configuraciÃ³n de la regla de agregaciÃ³n estÃ¡ en `artifacts/alphabetnet/a3_config.json`:

```json
{
  "rule": "votes_and_max",
  "k_min": 2,
  "tau_max": 0.5
}
```

## âš ï¸ LÃ­mites Conocidos

1. **Alfabeto fijo**: Solo soporta sÃ­mbolos A-L
2. **Longitud mÃ¡xima**: Prefijos se truncan a 64 caracteres
3. **SÃ­mbolos OOD**: Puede tener baja confianza en sÃ­mbolos raros
4. **Prefijos largos**: DegradaciÃ³n en prefijos > 63 caracteres

## ğŸ“ Licencia

[Especificar licencia]

## ğŸ™ Agradecimientos

[CrÃ©ditos y referencias]
