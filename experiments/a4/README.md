# Experimentos de AblaciÃ³n A4

Este directorio contiene los experimentos de ablaciÃ³n para comparar diferentes configuraciones del modelo AlphabetNet.

## ğŸ“ Estructura

```
experiments/a4/
â”œâ”€â”€ ablation_configs/          # Configuraciones de ablaciÃ³n
â”‚   â”œâ”€â”€ ablation_01.json
â”‚   â”œâ”€â”€ ablation_02.json
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ index.json
â”œâ”€â”€ ablation_results.csv       # Resultados de todos los experimentos
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ”§ Configuraciones

Las configuraciones varÃ­an en:

1. **RNN Type**: GRU vs LSTM
2. **Padding Mode**: right vs left
3. **Dropout**: 0.1 vs 0.3
4. **Automata Embedding**: on vs off

**Total**: 2 Ã— 2 Ã— 2 Ã— 2 = **16 configuraciones**

## ğŸš€ Uso

### 1. Generar Configuraciones

```bash
# Con automata embedding (16 configuraciones)
python tools/generate_ablation_configs.py --include-automata-emb

# Sin automata embedding (8 configuraciones)
python tools/generate_ablation_configs.py
```

### 2. Ejecutar Experimentos

```bash
python tools/run_ablation_experiments.py \
  --configs-dir experiments/a4/ablation_configs \
  --seeds 42 123 456 \
  --output-dir experiments/a4
```

**Nota**: Este script requiere que `train.py` sea modificado para aceptar parÃ¡metros de configuraciÃ³n. En una implementaciÃ³n real, necesitarÃ­as:

- Modificar `train.py` para leer configuraciones JSON
- Implementar padding left/right segÃºn configuraciÃ³n
- Pasar parÃ¡metros de dropout y RNN type al modelo
- Opcionalmente, habilitar/deshabilitar automata embedding

### 3. Analizar Resultados

```bash
python tools/analyze_ablation_results.py \
  --results experiments/a4/ablation_results.csv \
  --configs-dir experiments/a4/ablation_configs \
  --output-dir reports/figures \
  --report reports/A4_ablation.md
```

## ğŸ“Š MÃ©tricas Evaluadas

Para cada experimento se mide:

### ValidaciÃ³n
- **auPRC macro**: Average Precision macro promedio
- **auPRC micro**: Average Precision micro promedio
- **AP por sÃ­mbolo**: Average Precision individual por sÃ­mbolo A-L
- **ECE**: Expected Calibration Error

### Robustez SintÃ©tica
- **FPR_out@Ï„**: False Positive Rate de sÃ­mbolos fuera de Î£_ref
- **AUC_in-vs-out**: AUC de separabilidad in-Î£ vs out-of-Î£

### Coste
- **ParÃ¡metros totales**: NÃºmero de parÃ¡metros del modelo
- **Tiempo/Ã©poca**: Tiempo de entrenamiento por Ã©poca
- **Latencia por batch**: Tiempo de inferencia por batch

## ğŸ¯ Criterios de DecisiÃ³n

La mejor configuraciÃ³n se selecciona basÃ¡ndose en:

1. **Mayor auPRC Macro** (peso 50%)
2. **Menor FPR Out-of-Î£** (peso 30%)
3. **Latencia Aceptable** (peso 20%)

En caso de empates, se favorece GRU sobre LSTM por eficiencia.

## ğŸ“ Protocolo

- **Splits**: Mismos splits de A1
- **pos_weight**: Mismo cÃ¡lculo de pos_weight
- **Paciencia**: Misma paciencia para early stopping
- **Learning Rate**: Mismo learning rate inicial
- **Seeds**: 3 seeds por configuraciÃ³n (promedio y desviaciÃ³n estÃ¡ndar)

## ğŸ“ˆ Visualizaciones Generadas

- `reports/figures/ablation_pr_macro.png`: auPRC Macro por configuraciÃ³n
- `reports/figures/ablation_fpr_out.png`: FPR Out-of-Î£ por configuraciÃ³n
- `reports/figures/ablation_latency.png`: Latencia por configuraciÃ³n

## ğŸ“„ Reporte

El reporte final (`reports/A4_ablation.md`) incluye:

- Resumen ejecutivo
- Mejor configuraciÃ³n seleccionada
- ComparaciÃ³n de configuraciones (Top-5)
- AnÃ¡lisis por factor (RNN type, padding, dropout, etc.)
- Conclusiones y justificaciÃ³n

